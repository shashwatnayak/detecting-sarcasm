{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from textblob import TextBlob\n",
    "import numpy as np\n",
    "\n",
    "dict_sad={\":-(\":\"SAD\", \":(\":\"SAD\", \":-|\":\"SAD\",  \";-(\":\"SAD\", \";-<\":\"SAD\", \"|-{\":\"SAD\"}\n",
    "dict_happy={\":-)\":\"HAPPY\",\":)\":\"HAPPY\", \":o)\":\"HAPPY\",\":-}\":\"HAPPY\",\";-}\":\"HAPPY\",\":->\":\"HAPPY\",\";-)\":\"HAPPY\"}\n",
    "\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "\n",
    "def replace_emotion(sentence):\n",
    "    returnsent = sentence    \n",
    "    for i in dict_happy:\n",
    "        returnsent = returnsent.replace(i,dict_happy[i])\n",
    "    for i in dict_sad:\n",
    "        returnsent = returnsent.replace(i,dict_sad[i])\n",
    "    return returnsent\n",
    "\n",
    "\n",
    "def getbigramfeatures(features,sentence):\n",
    "    tokens = tokenizer.tokenize(sentence)\n",
    "    lemmas = [wordnet_lemmatizer.lemmatize(word) for word in tokens]\n",
    "    bigrams = nltk.bigrams(lemmas)\n",
    "    bigrams = [part[0]+' '+part[1] for part in bigrams]\n",
    "    bigramfeat = lemmas + bigrams\n",
    "    \n",
    "    for feat in bigramfeat:\n",
    "        features['contains(%s)' % feat] = 1.0\n",
    "        \n",
    "def gethalfSentimentfeatures(features,sentence):\n",
    "    tokens = tokenizer.tokenize(sentence)\n",
    "    \n",
    "    if len(tokens)==1:\n",
    "        tokens+=['.']\n",
    "    f_half = tokens[0:len(tokens)/2]\n",
    "    s_half = tokens[len(tokens)/2:]\n",
    "    \n",
    "    try:\n",
    "        blob = TextBlob(\"\".join([\" \"+i if not i.startswith(\"'\") and i not in string.punctuation else i for i in f_half]).strip())\n",
    "\n",
    "        features['sentiment fhalf'] = blob.sentiment.polarity\n",
    "        features['subjective fhalf'] = blob.sentiment.subjectivity\n",
    "        \n",
    "    except:\n",
    "        features['sentiment fhalf'] = 0.0\n",
    "        features['subjective fhalf'] = 0.0\n",
    "        \n",
    "    try:\n",
    "        blob = TextBlob(\"\".join([\" \"+i if not i.startswith(\"'\") and i not in string.punctuation else i for i in s_half]).strip())\n",
    "\n",
    "        features['sentiment shalf'] = blob.sentiment.polarity\n",
    "        features['subjective shalf'] = blob.sentiment.subjectivity\n",
    "        \n",
    "    except:\n",
    "        features['sentiment shalf'] = 0.0\n",
    "        features['subjective shalf'] = 0.0\n",
    "        \n",
    "    features['sentiment halfcontrast'] = np.abs(features['sentiment fhalf'] - features['sentiment shalf'])\n",
    "\n",
    "\n",
    "def getthirdSentimentfeatures(features,sentence):\n",
    "    tokens = tokenizer.tokenize(sentence)\n",
    "    #Split in 3\n",
    "    if len(tokens)==2:\n",
    "        tokens+=['.']\n",
    "    f_half = tokens[0:len(tokens)/3]\n",
    "    s_half = tokens[len(tokens)/3:2*len(tokens)/3]\n",
    "    t_half = tokens[2*len(tokens)/3:]\n",
    "    \n",
    "    try:\n",
    "        blob = TextBlob(\"\".join([\" \"+i if not i.startswith(\"'\") and i not in string.punctuation else i for i in f_half]).strip())\n",
    "\n",
    "        features['sentiment fthird'] = blob.sentiment.polarity\n",
    "        features['subjective fthird'] = blob.sentiment.subjectivity\n",
    "        \n",
    "    except:\n",
    "        features['sentiment fthird'] = 0.0\n",
    "        features['subjective fthird'] = 0.0\n",
    "        \n",
    "    try:\n",
    "        blob = TextBlob(\"\".join([\" \"+i if not i.startswith(\"'\") and i not in string.punctuation else i for i in s_half]).strip())\n",
    "\n",
    "        features['sentiment sthird'] = blob.sentiment.polarity\n",
    "        features['subjective sthird'] = blob.sentiment.subjectivity\n",
    "        \n",
    "    except:\n",
    "        features['sentiment sthird'] = 0.0\n",
    "        features['subjective sthird'] = 0.0\n",
    "        \n",
    "    try:\n",
    "        blob = TextBlob(\"\".join([\" \"+i if not i.startswith(\"'\") and i not in string.punctuation else i for i in t_half]).strip())\n",
    "\n",
    "        features['sentiment tthird'] = blob.sentiment.polarity\n",
    "        features['subjective tthird'] = blob.sentiment.subjectivity\n",
    "        \n",
    "    except:\n",
    "        features['sentiment tthird'] = 0.0\n",
    "        features['subjective tthird'] = 0.0\n",
    "        \n",
    "    features['sentiment 12contrast'] = np.abs(features['sentiment fthird'] - features['sentiment sthird'])\n",
    "    features['sentiment 13contrast'] = np.abs(features['sentiment fthird'] - features['sentiment tthird'])\n",
    "    features['sentiment 23contrast'] = np.abs(features['sentiment sthird'] - features['sentiment tthird'])\n",
    "\n",
    "\n",
    "def getPOSfeature(features, sentence):\n",
    "    tokens = tokenizer.tokenize(sentence)\n",
    "\n",
    "    tokens = [tok.lower() for tok in tokens]\n",
    "    pos_vector = nltk.pos_tag(tokens)\n",
    "    vector = np.zeros(4)\n",
    "\n",
    "    for j in range(len(pos_vector)):\n",
    "        pos=pos_vector[j][1]\n",
    "        if pos[0:2] == 'NN':   #noun\n",
    "            vector[0]+=1\n",
    "        elif pos[0:2] == 'JJ':\t#adjective\n",
    "            vector[1]+=1\t\n",
    "        elif pos[0:2] == 'VB': #verb\n",
    "            vector[2]+=1\n",
    "        elif pos[0:2] == 'RB':\t#adverb\n",
    "            vector[3]+=1\n",
    "      \n",
    "    for j in range(len(vector)):\n",
    "        features['POS' + str(j+1)] = vector[j]\n",
    "\n",
    "def getCapitalfeature(features,sentence):\n",
    "    count = 0\n",
    "    threshold = 4\n",
    "    for j in range(len(sentence)):\n",
    "        count +=int(sentence[j].isupper())\n",
    "    features['Capital'] = int(count>=threshold)\n",
    "\n",
    "def getExclamationCnt(features,sentence):\n",
    "    count =0;\n",
    "    for i in range(len(sentence)):\n",
    "        count += int(sentence[i] == '!')\n",
    "    \n",
    "    features['exclamation'] = count\n",
    "    \n",
    "def count_emotion(features,sentence):\n",
    "    returnsent = sentence\n",
    "    happy = 0;\n",
    "    sad = 0    \n",
    "    for i in dict_happy:\n",
    "        happy += returnsent.count(i)\n",
    "    for i in dict_sad:\n",
    "        sad += returnsent.count(i)\n",
    "    features['happyemo'] = happy\n",
    "    features['sademo'] = sad\n",
    "\n",
    "def getallfeatureset(sent):\n",
    "    features = {}\n",
    "    getCapitalfeature(features,sent)\n",
    "    getExclamationCnt(features,sent)\n",
    "    count_emotion(features,sent)\n",
    "    sent = replace_emotion(sent)\n",
    "    getbigramfeatures(features,sent)\n",
    "    gethalfSentimentfeatures(features,sent)\n",
    "    getthirdSentimentfeatures(features,sent)\n",
    "    getPOSfeature(features,sent)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Capital': 0,\n",
       " 'POS1': 3.0,\n",
       " 'POS2': 3.0,\n",
       " 'POS3': 6.0,\n",
       " 'POS4': 0.0,\n",
       " 'contains(I want)': 1.0,\n",
       " 'contains(I)': 1.0,\n",
       " 'contains(The best)': 1.0,\n",
       " 'contains(The)': 1.0,\n",
       " 'contains(able to)': 1.0,\n",
       " 'contains(able)': 1.0,\n",
       " 'contains(any woman)': 1.0,\n",
       " 'contains(any)': 1.0,\n",
       " 'contains(being able)': 1.0,\n",
       " 'contains(being single)': 1.0,\n",
       " 'contains(being)': 1.0,\n",
       " 'contains(best part)': 1.0,\n",
       " 'contains(best)': 1.0,\n",
       " 'contains(choose any)': 1.0,\n",
       " 'contains(choose)': 1.0,\n",
       " 'contains(down)': 1.0,\n",
       " 'contains(is being)': 1.0,\n",
       " 'contains(is)': 1.0,\n",
       " 'contains(me down)': 1.0,\n",
       " 'contains(me)': 1.0,\n",
       " 'contains(of being)': 1.0,\n",
       " 'contains(of)': 1.0,\n",
       " 'contains(part of)': 1.0,\n",
       " 'contains(part)': 1.0,\n",
       " 'contains(shoot me)': 1.0,\n",
       " 'contains(shoot)': 1.0,\n",
       " 'contains(single is)': 1.0,\n",
       " 'contains(single)': 1.0,\n",
       " 'contains(to choose)': 1.0,\n",
       " 'contains(to shoot)': 1.0,\n",
       " 'contains(to)': 1.0,\n",
       " 'contains(want to)': 1.0,\n",
       " 'contains(want)': 1.0,\n",
       " 'contains(woman I)': 1.0,\n",
       " 'contains(woman)': 1.0,\n",
       " 'exclamation': 0,\n",
       " 'happyemo': 0,\n",
       " 'sademo': 0,\n",
       " 'sentiment 12contrast': 0.0357142857142857,\n",
       " 'sentiment 13contrast': 0.6198412698412699,\n",
       " 'sentiment 23contrast': 0.6555555555555556,\n",
       " 'sentiment fhalf': 0.4761904761904762,\n",
       " 'sentiment fthird': 0.4642857142857143,\n",
       " 'sentiment halfcontrast': 0.6317460317460318,\n",
       " 'sentiment shalf': -0.15555555555555559,\n",
       " 'sentiment sthird': 0.5,\n",
       " 'sentiment tthird': -0.15555555555555559,\n",
       " 'subjective fhalf': 0.37976190476190474,\n",
       " 'subjective fthird': 0.2571428571428571,\n",
       " 'subjective shalf': 0.2888888888888889,\n",
       " 'subjective sthird': 0.625,\n",
       " 'subjective tthird': 0.2888888888888889}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getallfeatureset(\"The best part of being single is being able to choose any woman I want to shoot me down\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
